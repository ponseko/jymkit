{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"JymKit: A Lightweight Utility Library for JAX-based RL Projects","text":"<p>JymKit lets you</p> <ol> <li>\ud83d\udd79\ufe0f Import your favourite environments from various libraries with a single API and automatically wrap them to a common standard.</li> <li>\ud83d\ude80 Bootstrap new JAX RL projects with a single CLI command and get started instantly with a complete codebase.</li> <li>\ud83e\udd16 JymKit comes equiped with standard general RL implementations based on a near-single-file philosophy. You can either import these as off-the-shelf algorithms or copy over the code and tweak them for your problem. These algorithms follow the ideas of PureJaxRL for extremely fast end-to-end RL training in JAX.</li> </ol> <p>\ud83d\udcd6 More details over at the Documentation</p>"},{"location":"#getting-started","title":"\ud83d\ude80 Getting started","text":"<p>JymKit lets you bootstrap your new reinforcement learning projects directly from the command line. As such, for new projects, the easiest way to get started is via uv:</p> <pre><code>uvx jymkit &lt;projectname&gt;\nuv run example_train.py\n\n# ... or via pipx\npipx run jymkit &lt;projectname&gt;\n# activate a virtual environment in your preferred way, e.g. conda\npython example_train.py\n</code></pre> <p>This will set up a Python project folder structure with (optionally) an environment template and (optionally) algorithm code for you to tailor to your problem.</p> <p>For existing projects, you can simply install JymKit via <code>pip</code> and import the required functionality.</p> <pre><code>pip install jymkit\n</code></pre> <pre><code>import jax\nimport jymkit as jym\nfrom jymkit.algorithms import PPO\n\nenv = jym.make(\"CartPole\")\nenv = jymkit.LogWrapper(env)\nrng = jax.random.PRNGKey(0)\nagent = PPO(total_timesteps=5e5, learning_rate=2.5e-3)\nagent = agent.train(rng, env)\n</code></pre>"},{"location":"#environments","title":"\ud83c\udfe0 Environments","text":"<p>JymKit is not aimed at delivering a full environment suite. However, it does come equipped with a <code>jym.make(...)</code> command to import environments from existing suites (provided that these are installed) and wrap them appropriately to the JymKit API standard. For example, using environments from Gymnax:</p> <pre><code>import jymkit as jym\nfrom jymkit.algorithms import PPO\nimport jax\n\nenv = jym.make(\"Breakout-MinAtar\")\nenv = jym.FlattenObservationWrapper(env)\nenv = jym.LogWrapper(env)\n\nagent = PPO(**some_good_hyperparameters)\nagent = agent.train(jax.random.PRNGKey(0), env)\n\n# &gt; Using an environment from Gymnax via gymnax.make(Breakout-MinAtar).\n# &gt; Wrapping Gymnax environment with GymnaxWrapper\n# &gt;  Disable this behavior by passing wrapper=False\n# &gt; Wrapping environment in VecEnvWrapper\n# &gt; ... training results\n</code></pre> <p>Info</p> <p>For convenience, JymKit does include the 5 classic-control environments.</p> <p>Info</p> <p>Currently, importing from external libraries is possible for Gymnax and Brax. More are coming up!</p>"},{"location":"#environment-api","title":"Environment API","text":"<p>The JymKit API stays close to the somewhat established Gymnax API for the <code>reset()</code> and <code>step()</code> functions, but allows for truncated episodes in a manner closer to Gymnasium.</p> <pre><code>env = jym.make(...)\n\nobs, env_state = env.reset(key) # &lt;-- Mirroring Gymnax\n\n# env.step(): Gymnasium Timestep tuple with state information\n(obs, reward, terminated, truncated, info), env_state = env.step(key, state, action)\n</code></pre>"},{"location":"#algorithms","title":"\ud83e\udd16 Algorithms","text":"<p>Algorithms in <code>jymkit.algorithms</code> are built following a near-single-file implementation philosophy in mind. In contrast to implementations in CleanRL or PureJaxRL, JymKit algorithms are built in Equinox and follow a class-based design with a familiar Stable-Baselines API. </p> <p>Each algorithm supports both discrete- and continuous action/observation space -- adjusting based on the provided environment <code>observation_space</code> and <code>action_space</code>. Additionally, the implementations support multi-agent environments out of the box.</p> <pre><code>from jymkit.algorithms import PPO\nimport jax\n\nenv = ...\nagent = PPO(**some_good_hyperparameters)\nagent = agent.train(jax.random.PRNGKey(0), env)\n</code></pre> <p>Info</p> <p>Currently, only a <code>PPO</code> implementation is implemented. More will be included in the near future. However, the current goal is not to include as many algorithms as possible.</p>"},{"location":"api/Environment/","title":"Environment","text":""},{"location":"api/Environment/#src.jymkit.Environment","title":"<code>src.jymkit.Environment</code>","text":"<p>Base environment class for JAX-compatible environments. Create your environment by subclassing this.</p> <p><code>step</code> and <code>reset</code> should typically not be overridden, as they merely handle the auto-reset logic. Instead, the environment-specific logic should be implemented in the <code>step_env</code> and <code>reset_env</code> methods.</p>"},{"location":"api/Environment/#src.jymkit.Environment.step","title":"<code>step(key: PRNGKeyArray, state: TEnvState, action: PyTree[Real[Array, ...]]) -&gt; Tuple[TimeStep, TEnvState]</code>","text":"<p>Steps the environment forward with the given action and performs auto-reset when necessary. Additionally, this function inserts the original observation (before auto-resetting) in the info dictionary to bootstrap correctly on truncated episodes (<code>info={\"_TERMINAL_OBSERVATION\": obs, ...}</code>)</p> <p>This function should typically not be overridden. Instead, the environment-specific logic should be implemented in the <code>step_env</code> method.</p> <p>Returns a TimeStep object (observation, reward, terminated, truncated, info) and the new state.</p> <p>Arguments:</p> <ul> <li><code>key</code>: JAX PRNG key.</li> <li><code>state</code>: Current state of the environment.</li> <li><code>action</code>: Action to take in the environment.</li> </ul>"},{"location":"api/Environment/#src.jymkit.Environment.step_env","title":"<code>step_env(key: PRNGKeyArray, state: TEnvState, action: PyTree[Real[Array, ...]]) -&gt; Tuple[TimeStep, TEnvState]</code>  <code>abstractmethod</code>","text":"<p>Defines the environment-specific step logic. I.e. here the state of the environment is updated according to the transition function.</p> <p>Returns a <code>TimeStep</code> object (observation, reward, terminated, truncated, info) and the new state.</p> <p>Arguments:</p> <ul> <li><code>key</code>: JAX PRNG key.</li> <li><code>state</code>: Current state of the environment.</li> <li><code>action</code>: Action to take in the environment.</li> </ul>"},{"location":"api/Environment/#src.jymkit.Environment.reset","title":"<code>reset(key: PRNGKeyArray) -&gt; Tuple[TObservation, TEnvState]</code>","text":"<p>Resets the environment to an initial state and returns the initial observation. Environment-specific logic is defined in the <code>reset_env</code> method. Typically, this function should not be overridden.</p> <p>Returns the initial observation and the initial state of the environment.</p> <p>Arguments:</p> <ul> <li><code>key</code>: JAX PRNG key.</li> </ul>"},{"location":"api/Environment/#src.jymkit.Environment.reset_env","title":"<code>reset_env(key: PRNGKeyArray) -&gt; Tuple[TObservation, TEnvState]</code>  <code>abstractmethod</code>","text":"<p>Defines the environment-specific reset logic.</p> <p>Returns the initial observation and the initial state of the environment.</p> <p>Arguments:</p> <ul> <li><code>key</code>: JAX PRNG key.</li> </ul>"},{"location":"api/Environment/#src.jymkit.Environment.observation_space","title":"<code>observation_space: Space | PyTree[Space]</code>  <code>abstractmethod</code> <code>property</code>","text":"<p>Defines the space of possible observations from the environment. For multi-agent environments, this should be a PyTree of spaces. See <code>jymkit.spaces</code> for more information on how to define (composite) observation spaces.</p>"},{"location":"api/Environment/#src.jymkit.Environment.sample_observation","title":"<code>sample_observation(key: PRNGKeyArray) -&gt; TObservation</code>","text":"<p>Convenience method to sample a random observation from the environment's observation space. While one could use <code>self.observation_space.sample(key)</code>, this method additionally works on composite observation spaces.</p>"},{"location":"api/Environment/#src.jymkit.Environment.action_space","title":"<code>action_space: Space | PyTree[Space]</code>  <code>abstractmethod</code> <code>property</code>","text":"<p>Defines the space of valid actions for the environment. For multi-agent environments, this should be a PyTree of spaces. See <code>jymkit.spaces</code> for more information on how to define (composite) action spaces.</p>"},{"location":"api/Environment/#src.jymkit.Environment.sample_action","title":"<code>sample_action(key: PRNGKeyArray) -&gt; PyTree[Real[Array, ...]]</code>","text":"<p>Convenience method to sample a random action from the environment's action space. While one could use <code>self.action_space.sample(key)</code>, this method additionally works on composite action spaces.</p>"},{"location":"api/Environment/#timestep","title":"Timestep","text":""},{"location":"api/Environment/#src.jymkit.TimeStep","title":"<code>src.jymkit.TimeStep</code>","text":"<p>A container for the output of an environment's step function. (<code>timestep, state = env.step(...)</code>).</p> <p>This class follows the Gymnasium standard API, with the signature: <code>(obs, reward, terminated, truncated, info)</code> tuple.</p> <p>Attributes:</p> Name Type Description <code>observation</code> <code>Num[Array, ...] | PyTree[Num[Array, ...]] | PyTree[AgentObservation]</code> <p>The environment state representation provided to the agent.          Can be an Array or a PyTree of arrays.          When using action masking, the observation should be of type <code>AgentObservation</code>.</p> <code>reward</code> <code>Float[Array, ...] | PyTree[Float[Array, ...]]</code> <p>The reward signal from the previous action, indicating performance.     Can be a scalar Array or a PyTree of reward Arrays (in the case of multi agent-environments).</p> <code>terminated</code> <code>Bool[Array, ...] | PyTree[Bool[Array, ...]]</code> <p>Boolean flag indicating whether the episode has ended due to        reaching a terminal state (e.g., goal reached, game over).</p> <code>truncated</code> <code>Bool[Array, ...] | PyTree[Bool[Array, ...]]</code> <p>Boolean flag indicating whether the episode ended due to       external factors (e.g., reaching max steps, timeout).</p> <code>info</code> <code>dict</code> <p>Dictionary containing any additional information about the environment step.</p>"},{"location":"api/Environment/#observation-container-optional","title":"Observation container (optional)","text":""},{"location":"api/Environment/#src.jymkit.AgentObservation","title":"<code>src.jymkit.AgentObservation</code>","text":"<p>A container for the observation of a single agent, with optional action masking.</p> <p>Typically, this container is optional. However, Algorithms in <code>jymkit.algorithms</code> expect observations to be wrapped in this type when action masking is enabled.</p> <p>Arguments:</p> <ul> <li><code>observation</code>: The observation of the agent.</li> <li><code>action_mask</code>: The action mask of the agent. A boolean array of the same shape as the action space.</li> </ul>"},{"location":"api/Spaces/","title":"Spaces","text":""},{"location":"api/Spaces/#src.jymkit._wrappers.Space","title":"<code>src.jymkit._wrappers.Space</code>","text":"<p>The base class for all spaces in JymKit. Instead of using this class directly, use the subclasses <code>Box</code>, <code>Discrete</code>, and <code>MultiDiscrete</code>. Composite spaces can be created by simply combining spaces in an arbitrary PyTree. For example, a tuple of Box spaces can be created as follows: <pre><code>from jymkit import Box\n\nbox1 = Box(low=0, high=1, shape=(3,))\nbox2 = Box(low=0, high=1, shape=(4,))\nbox3 = Box(low=0, high=1, shape=(5,))\ncomposite_space = (box1, box2, box3)\n</code></pre></p> <p>JymKit algorithms assume multi-agent environments are such a composite space, where the first level of the PyTree is the agent dimension. For example, a multi-agent environment observation space may look like this: <pre><code>from jymkit import Box\nfrom jymkit import MultiDiscrete\n\nagent1_obs = Box(low=0, high=1, shape=(3,))\nagent2_obs = Box(low=0, high=1, shape=(4,))\nagent3_obs = MultiDiscrete(nvec=[2, 3])\nenv_obs_space = {\n    \"agent1\": agent1_obs,\n    \"agent2\": agent2_obs,\n    \"agent3\": agent3_obs,\n}\n</code></pre></p> <p>Spaces are purposefully not registered PyTree nodes.</p>"},{"location":"api/Spaces/#src.jymkit.Box","title":"<code>src.jymkit.Box</code>  <code>dataclass</code>","text":"<p>The standard Box space for continuous action/observation spaces.</p> <p>Arguments:</p> <ul> <li><code>low</code> (int / Array[int]): The lower bound of the space.</li> <li><code>high</code> (int / Array[int]): The upper bound of the space.</li> <li><code>shape</code>: The shape of the space.</li> <li><code>dtype</code>: The data type of the space. Default is jnp.float32.</li> </ul>"},{"location":"api/Spaces/#src.jymkit.Box.sample","title":"<code>sample(rng: PRNGKeyArray) -&gt; Array</code>","text":"<p>Sample random action uniformly from set of continuous choices.</p>"},{"location":"api/Spaces/#src.jymkit.Discrete","title":"<code>src.jymkit.Discrete</code>  <code>dataclass</code>","text":"<p>The standard discrete space for discrete action/observation spaces.</p> <p>Arguments:</p> <ul> <li><code>n</code> (int): The number of discrete actions.</li> <li><code>dtype</code>: The data type of the space. Default is jnp.int16.</li> </ul>"},{"location":"api/Spaces/#src.jymkit.Discrete.sample","title":"<code>sample(rng: PRNGKeyArray) -&gt; Int[Array, '']</code>","text":"<p>Sample random action uniformly from set of discrete choices.</p>"},{"location":"api/Spaces/#src.jymkit.MultiDiscrete","title":"<code>src.jymkit.MultiDiscrete</code>  <code>dataclass</code>","text":"<p>The standard multi-discrete space for discrete action/observation spaces.</p> <p>Arguments:</p> <ul> <li><code>nvec</code> (Array[int]): The number of discrete actions for each dimension.</li> <li><code>dtype</code>: The data type of the space. Default is jnp.int16.</li> </ul>"},{"location":"api/Spaces/#src.jymkit.MultiDiscrete.sample","title":"<code>sample(rng: PRNGKeyArray) -&gt; Int[Array, '']</code>","text":"<p>Sample random action uniformly from set of discrete choices.</p>"},{"location":"api/Wrappers/","title":"Wrappers","text":""},{"location":"api/Wrappers/#src.jymkit.LogWrapper","title":"<code>src.jymkit.LogWrapper</code>","text":"<p>Log the episode returns and lengths. Modeled after the LogWrapper in PureJaxRL.</p> <p>This wrapper inserts episode returns and lengths into the <code>info</code> dictionary of the <code>TimeStep</code> object. The <code>returned_episode_returns</code> and <code>returned_episode_lengths</code> are the returns and lengths of the last completed episode.</p> <p>After collecting a trajectory of <code>n</code> steps and collecting all the info dicts, the episode returns may be collected via: <pre><code>return_values = jax.tree.map(\n    lambda x: x[data[\"returned_episode\"]], data[\"returned_episode_returns\"]\n)\n</code></pre></p> <p>Arguments:</p> <ul> <li><code>_env</code>: Environment to wrap.</li> </ul>"},{"location":"api/Wrappers/#src.jymkit.LogWrapper.step_env","title":"<code>step_env(key: PRNGKeyArray, state: TEnvState, action: PyTree[Real[Array, ...]]) -&gt; Tuple[TimeStep, TEnvState]</code>","text":""},{"location":"api/Wrappers/#src.jymkit.LogWrapper.reset_env","title":"<code>reset_env(key: PRNGKeyArray) -&gt; Tuple[TObservation, TEnvState]</code>","text":""},{"location":"api/Wrappers/#src.jymkit.LogWrapper.action_space","title":"<code>action_space: Space | PyTree[Space]</code>  <code>property</code>","text":""},{"location":"api/Wrappers/#src.jymkit.LogWrapper.observation_space","title":"<code>observation_space: Space | PyTree[Space]</code>  <code>property</code>","text":""},{"location":"api/Wrappers/#src.jymkit.LogWrapper.auto_reset","title":"<code>auto_reset(key: PRNGKeyArray, timestep_step: TimeStep, state_step: TEnvState) -&gt; Tuple[TimeStep, TEnvState]</code>","text":"<p>Auto-resets the environment when the episode is terminated or truncated.</p> <p>Given a step timestep and state, this function will auto-reset the environment and return the new timestep and state when the episode is terminated or truncated. Inserts the original observation in info to bootstrap correctly on truncated episodes.</p> <p>Arguments:</p> <ul> <li><code>key</code>: JAX PRNG key.</li> <li><code>timestep_step</code>: The timestep returned by the <code>step_env</code> method.</li> <li><code>state_step</code>: The state returned by the <code>step_env</code> method.</li> </ul> <p>Returns: A tuple of the new timestep and state with the state and observation reset to a new initial state and observation when the episode is terminated or truncated. The original observation is inserted in info to bootstrap correctly on truncated episodes.</p>"},{"location":"api/Wrappers/#src.jymkit.LogWrapper.sample_action","title":"<code>sample_action(key: PRNGKeyArray) -&gt; PyTree[Real[Array, ...]]</code>","text":"<p>Convenience method to sample a random action from the environment's action space. While one could use <code>self.action_space.sample(key)</code>, this method additionally works on composite action spaces.</p>"},{"location":"api/Wrappers/#src.jymkit.LogWrapper.sample_observation","title":"<code>sample_observation(key: PRNGKeyArray) -&gt; TObservation</code>","text":"<p>Convenience method to sample a random observation from the environment's observation space. While one could use <code>self.observation_space.sample(key)</code>, this method additionally works on composite observation spaces.</p>"},{"location":"api/Wrappers/#src.jymkit.LogWrapper.multi_agent","title":"<code>multi_agent: bool</code>  <code>property</code>","text":""},{"location":"api/Wrappers/#src.jymkit.LogWrapper.agent_structure","title":"<code>agent_structure: PyTreeDef</code>  <code>property</code>","text":"<p>Returns the structure of the agent space. This is useful for environments with multiple agents.</p>"},{"location":"api/Wrappers/#src.jymkit.LogWrapper._env","title":"<code>_env: Environment</code>  <code>instance-attribute</code>","text":""},{"location":"api/Wrappers/#src.jymkit.LogWrapper.__getattr__","title":"<code>__getattr__(name)</code>","text":""},{"location":"api/Wrappers/#src.jymkit.VecEnvWrapper","title":"<code>src.jymkit.VecEnvWrapper</code>","text":"<p>Wrapper to vectorize environments. Simply calls <code>jax.vmap</code> on the <code>reset</code> and <code>step</code> methods of the environment. The number of environmnents is determined by the leading axis of the inputs to the <code>reset</code> and <code>step</code> methods, as if you would call <code>jax.vmap</code> directly.</p> <p>We use a wrapper instead of <code>jax.vmap</code> in each algorithm directly to control where the vectorization happens. This allows other wrappers to act on the vectorized environment, e.g. <code>NormalizeVecObsWrapper</code> and <code>NormalizeVecRewardWrapper</code>.</p>"},{"location":"api/Wrappers/#src.jymkit.VecEnvWrapper.step_env","title":"<code>step_env(key: PRNGKeyArray, state: TEnvState, action: PyTree[Real[Array, ...]]) -&gt; Tuple[TimeStep, TEnvState]</code>","text":""},{"location":"api/Wrappers/#src.jymkit.VecEnvWrapper.reset_env","title":"<code>reset_env(key: PRNGKeyArray) -&gt; Tuple[TObservation, TEnvState]</code>","text":""},{"location":"api/Wrappers/#src.jymkit.VecEnvWrapper.action_space","title":"<code>action_space: Space | PyTree[Space]</code>  <code>property</code>","text":""},{"location":"api/Wrappers/#src.jymkit.VecEnvWrapper.observation_space","title":"<code>observation_space: Space | PyTree[Space]</code>  <code>property</code>","text":""},{"location":"api/Wrappers/#src.jymkit.VecEnvWrapper.auto_reset","title":"<code>auto_reset(key: PRNGKeyArray, timestep_step: TimeStep, state_step: TEnvState) -&gt; Tuple[TimeStep, TEnvState]</code>","text":"<p>Auto-resets the environment when the episode is terminated or truncated.</p> <p>Given a step timestep and state, this function will auto-reset the environment and return the new timestep and state when the episode is terminated or truncated. Inserts the original observation in info to bootstrap correctly on truncated episodes.</p> <p>Arguments:</p> <ul> <li><code>key</code>: JAX PRNG key.</li> <li><code>timestep_step</code>: The timestep returned by the <code>step_env</code> method.</li> <li><code>state_step</code>: The state returned by the <code>step_env</code> method.</li> </ul> <p>Returns: A tuple of the new timestep and state with the state and observation reset to a new initial state and observation when the episode is terminated or truncated. The original observation is inserted in info to bootstrap correctly on truncated episodes.</p>"},{"location":"api/Wrappers/#src.jymkit.VecEnvWrapper.sample_action","title":"<code>sample_action(key: PRNGKeyArray) -&gt; PyTree[Real[Array, ...]]</code>","text":"<p>Convenience method to sample a random action from the environment's action space. While one could use <code>self.action_space.sample(key)</code>, this method additionally works on composite action spaces.</p>"},{"location":"api/Wrappers/#src.jymkit.VecEnvWrapper.sample_observation","title":"<code>sample_observation(key: PRNGKeyArray) -&gt; TObservation</code>","text":"<p>Convenience method to sample a random observation from the environment's observation space. While one could use <code>self.observation_space.sample(key)</code>, this method additionally works on composite observation spaces.</p>"},{"location":"api/Wrappers/#src.jymkit.VecEnvWrapper.multi_agent","title":"<code>multi_agent: bool</code>  <code>property</code>","text":""},{"location":"api/Wrappers/#src.jymkit.VecEnvWrapper.agent_structure","title":"<code>agent_structure: PyTreeDef</code>  <code>property</code>","text":"<p>Returns the structure of the agent space. This is useful for environments with multiple agents.</p>"},{"location":"api/Wrappers/#src.jymkit.VecEnvWrapper._env","title":"<code>_env: Environment</code>  <code>instance-attribute</code>","text":""},{"location":"api/Wrappers/#src.jymkit.VecEnvWrapper.__getattr__","title":"<code>__getattr__(name)</code>","text":""},{"location":"api/Wrappers/#src.jymkit.NormalizeVecObsWrapper","title":"<code>src.jymkit.NormalizeVecObsWrapper</code>","text":"<p>Normalize the observations of the environment via running mean and variance. This wrapper acts on vectorized environments and in turn should be wrapped within a <code>VecEnvWrapper</code>.</p> <p>Arguments:</p> <ul> <li><code>_env</code>: Environment to wrap.</li> </ul>"},{"location":"api/Wrappers/#src.jymkit.NormalizeVecObsWrapper.step_env","title":"<code>step_env(key: PRNGKeyArray, state: TEnvState, action: PyTree[Real[Array, ...]]) -&gt; Tuple[TimeStep, TEnvState]</code>","text":""},{"location":"api/Wrappers/#src.jymkit.NormalizeVecObsWrapper.reset_env","title":"<code>reset_env(key: PRNGKeyArray) -&gt; Tuple[TObservation, TEnvState]</code>","text":""},{"location":"api/Wrappers/#src.jymkit.NormalizeVecObsWrapper.action_space","title":"<code>action_space: Space | PyTree[Space]</code>  <code>property</code>","text":""},{"location":"api/Wrappers/#src.jymkit.NormalizeVecObsWrapper.observation_space","title":"<code>observation_space: Space | PyTree[Space]</code>  <code>property</code>","text":""},{"location":"api/Wrappers/#src.jymkit.NormalizeVecObsWrapper.auto_reset","title":"<code>auto_reset(key: PRNGKeyArray, timestep_step: TimeStep, state_step: TEnvState) -&gt; Tuple[TimeStep, TEnvState]</code>","text":"<p>Auto-resets the environment when the episode is terminated or truncated.</p> <p>Given a step timestep and state, this function will auto-reset the environment and return the new timestep and state when the episode is terminated or truncated. Inserts the original observation in info to bootstrap correctly on truncated episodes.</p> <p>Arguments:</p> <ul> <li><code>key</code>: JAX PRNG key.</li> <li><code>timestep_step</code>: The timestep returned by the <code>step_env</code> method.</li> <li><code>state_step</code>: The state returned by the <code>step_env</code> method.</li> </ul> <p>Returns: A tuple of the new timestep and state with the state and observation reset to a new initial state and observation when the episode is terminated or truncated. The original observation is inserted in info to bootstrap correctly on truncated episodes.</p>"},{"location":"api/Wrappers/#src.jymkit.NormalizeVecObsWrapper.sample_action","title":"<code>sample_action(key: PRNGKeyArray) -&gt; PyTree[Real[Array, ...]]</code>","text":"<p>Convenience method to sample a random action from the environment's action space. While one could use <code>self.action_space.sample(key)</code>, this method additionally works on composite action spaces.</p>"},{"location":"api/Wrappers/#src.jymkit.NormalizeVecObsWrapper.sample_observation","title":"<code>sample_observation(key: PRNGKeyArray) -&gt; TObservation</code>","text":"<p>Convenience method to sample a random observation from the environment's observation space. While one could use <code>self.observation_space.sample(key)</code>, this method additionally works on composite observation spaces.</p>"},{"location":"api/Wrappers/#src.jymkit.NormalizeVecObsWrapper.multi_agent","title":"<code>multi_agent: bool</code>  <code>property</code>","text":""},{"location":"api/Wrappers/#src.jymkit.NormalizeVecObsWrapper.agent_structure","title":"<code>agent_structure: PyTreeDef</code>  <code>property</code>","text":"<p>Returns the structure of the agent space. This is useful for environments with multiple agents.</p>"},{"location":"api/Wrappers/#src.jymkit.NormalizeVecObsWrapper._env","title":"<code>_env: Environment</code>  <code>instance-attribute</code>","text":""},{"location":"api/Wrappers/#src.jymkit.NormalizeVecObsWrapper.__getattr__","title":"<code>__getattr__(name)</code>","text":""},{"location":"api/Wrappers/#src.jymkit.NormalizeVecRewardWrapper","title":"<code>src.jymkit.NormalizeVecRewardWrapper</code>","text":"<p>Normalize the rewards of the environment via running mean and variance. This wrapper acts on vectorized environments and in turn should be wrapped within a <code>VecEnvWrapper</code>.</p> <p>Arguments:</p> <ul> <li><code>_env</code>: Environment to wrap.</li> <li><code>gamma</code>: Discount factor for the rewards.</li> </ul>"},{"location":"api/Wrappers/#src.jymkit.NormalizeVecRewardWrapper.step_env","title":"<code>step_env(key: PRNGKeyArray, state: TEnvState, action: PyTree[Real[Array, ...]]) -&gt; Tuple[TimeStep, TEnvState]</code>","text":""},{"location":"api/Wrappers/#src.jymkit.NormalizeVecRewardWrapper.reset_env","title":"<code>reset_env(key: PRNGKeyArray) -&gt; Tuple[TObservation, TEnvState]</code>","text":""},{"location":"api/Wrappers/#src.jymkit.NormalizeVecRewardWrapper.action_space","title":"<code>action_space: Space | PyTree[Space]</code>  <code>property</code>","text":""},{"location":"api/Wrappers/#src.jymkit.NormalizeVecRewardWrapper.observation_space","title":"<code>observation_space: Space | PyTree[Space]</code>  <code>property</code>","text":""},{"location":"api/Wrappers/#src.jymkit.NormalizeVecRewardWrapper.auto_reset","title":"<code>auto_reset(key: PRNGKeyArray, timestep_step: TimeStep, state_step: TEnvState) -&gt; Tuple[TimeStep, TEnvState]</code>","text":"<p>Auto-resets the environment when the episode is terminated or truncated.</p> <p>Given a step timestep and state, this function will auto-reset the environment and return the new timestep and state when the episode is terminated or truncated. Inserts the original observation in info to bootstrap correctly on truncated episodes.</p> <p>Arguments:</p> <ul> <li><code>key</code>: JAX PRNG key.</li> <li><code>timestep_step</code>: The timestep returned by the <code>step_env</code> method.</li> <li><code>state_step</code>: The state returned by the <code>step_env</code> method.</li> </ul> <p>Returns: A tuple of the new timestep and state with the state and observation reset to a new initial state and observation when the episode is terminated or truncated. The original observation is inserted in info to bootstrap correctly on truncated episodes.</p>"},{"location":"api/Wrappers/#src.jymkit.NormalizeVecRewardWrapper.sample_action","title":"<code>sample_action(key: PRNGKeyArray) -&gt; PyTree[Real[Array, ...]]</code>","text":"<p>Convenience method to sample a random action from the environment's action space. While one could use <code>self.action_space.sample(key)</code>, this method additionally works on composite action spaces.</p>"},{"location":"api/Wrappers/#src.jymkit.NormalizeVecRewardWrapper.sample_observation","title":"<code>sample_observation(key: PRNGKeyArray) -&gt; TObservation</code>","text":"<p>Convenience method to sample a random observation from the environment's observation space. While one could use <code>self.observation_space.sample(key)</code>, this method additionally works on composite observation spaces.</p>"},{"location":"api/Wrappers/#src.jymkit.NormalizeVecRewardWrapper.multi_agent","title":"<code>multi_agent: bool</code>  <code>property</code>","text":""},{"location":"api/Wrappers/#src.jymkit.NormalizeVecRewardWrapper.agent_structure","title":"<code>agent_structure: PyTreeDef</code>  <code>property</code>","text":"<p>Returns the structure of the agent space. This is useful for environments with multiple agents.</p>"},{"location":"api/Wrappers/#src.jymkit.NormalizeVecRewardWrapper._env","title":"<code>_env: Environment</code>  <code>instance-attribute</code>","text":""},{"location":"api/Wrappers/#src.jymkit.NormalizeVecRewardWrapper.__getattr__","title":"<code>__getattr__(name)</code>","text":""},{"location":"api/Wrappers/#src.jymkit.FlattenObservationWrapper","title":"<code>src.jymkit.FlattenObservationWrapper</code>","text":"<p>Flatten the observations of the environment.</p> <p>Flattens each observation in the environment to a single vector. When the observation is a PyTree of arrays, it flattens each array and returns the same PyTree structure with the flattened arrays.</p> <p>Arguments:</p> <ul> <li><code>_env</code>: Environment to wrap.</li> </ul>"},{"location":"api/Wrappers/#src.jymkit.FlattenObservationWrapper.step_env","title":"<code>step_env(key: PRNGKeyArray, state: TEnvState, action: PyTree[Real[Array, ...]]) -&gt; Tuple[TimeStep, TEnvState]</code>","text":""},{"location":"api/Wrappers/#src.jymkit.FlattenObservationWrapper.reset_env","title":"<code>reset_env(key: PRNGKeyArray) -&gt; Tuple[TObservation, TEnvState]</code>","text":""},{"location":"api/Wrappers/#src.jymkit.FlattenObservationWrapper.action_space","title":"<code>action_space: Space | PyTree[Space]</code>  <code>property</code>","text":""},{"location":"api/Wrappers/#src.jymkit.FlattenObservationWrapper.auto_reset","title":"<code>auto_reset(key: PRNGKeyArray, timestep_step: TimeStep, state_step: TEnvState) -&gt; Tuple[TimeStep, TEnvState]</code>","text":"<p>Auto-resets the environment when the episode is terminated or truncated.</p> <p>Given a step timestep and state, this function will auto-reset the environment and return the new timestep and state when the episode is terminated or truncated. Inserts the original observation in info to bootstrap correctly on truncated episodes.</p> <p>Arguments:</p> <ul> <li><code>key</code>: JAX PRNG key.</li> <li><code>timestep_step</code>: The timestep returned by the <code>step_env</code> method.</li> <li><code>state_step</code>: The state returned by the <code>step_env</code> method.</li> </ul> <p>Returns: A tuple of the new timestep and state with the state and observation reset to a new initial state and observation when the episode is terminated or truncated. The original observation is inserted in info to bootstrap correctly on truncated episodes.</p>"},{"location":"api/Wrappers/#src.jymkit.FlattenObservationWrapper.sample_action","title":"<code>sample_action(key: PRNGKeyArray) -&gt; PyTree[Real[Array, ...]]</code>","text":"<p>Convenience method to sample a random action from the environment's action space. While one could use <code>self.action_space.sample(key)</code>, this method additionally works on composite action spaces.</p>"},{"location":"api/Wrappers/#src.jymkit.FlattenObservationWrapper.sample_observation","title":"<code>sample_observation(key: PRNGKeyArray) -&gt; TObservation</code>","text":"<p>Convenience method to sample a random observation from the environment's observation space. While one could use <code>self.observation_space.sample(key)</code>, this method additionally works on composite observation spaces.</p>"},{"location":"api/Wrappers/#src.jymkit.FlattenObservationWrapper.multi_agent","title":"<code>multi_agent: bool</code>  <code>property</code>","text":""},{"location":"api/Wrappers/#src.jymkit.FlattenObservationWrapper.agent_structure","title":"<code>agent_structure: PyTreeDef</code>  <code>property</code>","text":"<p>Returns the structure of the agent space. This is useful for environments with multiple agents.</p>"},{"location":"api/Wrappers/#src.jymkit.FlattenObservationWrapper._env","title":"<code>_env: Environment</code>  <code>instance-attribute</code>","text":""},{"location":"api/Wrappers/#src.jymkit.FlattenObservationWrapper.__getattr__","title":"<code>__getattr__(name)</code>","text":""},{"location":"api/Wrappers/#src.jymkit.GymnaxWrapper","title":"<code>src.jymkit.GymnaxWrapper</code>","text":"<p>Wrapper for Gymnax environments to transform them into the Jymkit environment interface.</p> <p>Arguments:</p> <ul> <li><code>_env</code>: Gymnax environment.</li> <li><code>handle_truncation</code>: If True, the wrapper will reimplement the autoreset behavior to include     truncated information and the terminal_observation in the info dictionary. If False, the wrapper will mirror     the Gymnax behavior by ignoring truncations. Default=True.</li> </ul>"},{"location":"api/Wrappers/#src.jymkit.GymnaxWrapper.step_env","title":"<code>step_env(key: PRNGKeyArray, state: TEnvState, action: PyTree[Real[Array, ...]]) -&gt; Tuple[TimeStep, TEnvState]</code>","text":""},{"location":"api/Wrappers/#src.jymkit.GymnaxWrapper.reset_env","title":"<code>reset_env(key: PRNGKeyArray) -&gt; Tuple[TObservation, TEnvState]</code>","text":""},{"location":"api/Wrappers/#src.jymkit.GymnaxWrapper.auto_reset","title":"<code>auto_reset(key: PRNGKeyArray, timestep_step: TimeStep, state_step: TEnvState) -&gt; Tuple[TimeStep, TEnvState]</code>","text":"<p>Auto-resets the environment when the episode is terminated or truncated.</p> <p>Given a step timestep and state, this function will auto-reset the environment and return the new timestep and state when the episode is terminated or truncated. Inserts the original observation in info to bootstrap correctly on truncated episodes.</p> <p>Arguments:</p> <ul> <li><code>key</code>: JAX PRNG key.</li> <li><code>timestep_step</code>: The timestep returned by the <code>step_env</code> method.</li> <li><code>state_step</code>: The state returned by the <code>step_env</code> method.</li> </ul> <p>Returns: A tuple of the new timestep and state with the state and observation reset to a new initial state and observation when the episode is terminated or truncated. The original observation is inserted in info to bootstrap correctly on truncated episodes.</p>"},{"location":"api/Wrappers/#src.jymkit.GymnaxWrapper.sample_action","title":"<code>sample_action(key: PRNGKeyArray) -&gt; PyTree[Real[Array, ...]]</code>","text":"<p>Convenience method to sample a random action from the environment's action space. While one could use <code>self.action_space.sample(key)</code>, this method additionally works on composite action spaces.</p>"},{"location":"api/Wrappers/#src.jymkit.GymnaxWrapper.sample_observation","title":"<code>sample_observation(key: PRNGKeyArray) -&gt; TObservation</code>","text":"<p>Convenience method to sample a random observation from the environment's observation space. While one could use <code>self.observation_space.sample(key)</code>, this method additionally works on composite observation spaces.</p>"},{"location":"api/Wrappers/#src.jymkit.GymnaxWrapper.multi_agent","title":"<code>multi_agent: bool</code>  <code>property</code>","text":""},{"location":"api/Wrappers/#src.jymkit.GymnaxWrapper.agent_structure","title":"<code>agent_structure: PyTreeDef</code>  <code>property</code>","text":"<p>Returns the structure of the agent space. This is useful for environments with multiple agents.</p>"},{"location":"api/Wrappers/#src.jymkit.GymnaxWrapper.__getattr__","title":"<code>__getattr__(name)</code>","text":""},{"location":"api/Wrappers/#utility-functions","title":"Utility functions","text":""},{"location":"api/Wrappers/#src.jymkit.is_wrapped","title":"<code>src.jymkit.is_wrapped(wrapped_env: Environment, wrapper_class: type | str) -&gt; bool</code>","text":"<p>Check if the environment is wrapped with a specific wrapper class.</p>"},{"location":"api/Wrappers/#src.jymkit.remove_wrapper","title":"<code>src.jymkit.remove_wrapper(wrapped_env: Environment, wrapper_class: type) -&gt; Environment</code>","text":"<p>Remove a specific wrapper class from the environment.</p>"}]}